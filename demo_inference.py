"""
SAHI æ¨ç†å¯¹æ¯”è„šæœ¬ - æ¼”ç¤º SAHI åˆ‡ç‰‡æ¨ç† vs åŸç”Ÿ YOLO æ¨ç†çš„æ•ˆæœå¯¹æ¯”

ã€ä½œç”¨ã€‘
- æ¼”ç¤º SAHI åˆ‡ç‰‡æ¨ç†å’ŒåŸç”Ÿ YOLO æ¨ç†çš„å¯¹æ¯”æ•ˆæœ
- éªŒè¯ P2 æ¨¡å‹åœ¨é«˜åˆ†è¾¨ç‡èˆªæ‹å›¾åƒä¸Šçš„å¾®å°ç›®æ ‡æ£€æµ‹èƒ½åŠ›
- è¾“å‡ºå¯è§†åŒ–ç»“æœå’Œæ£€æµ‹æ•°é‡å¯¹æ¯”

ã€ä¸»è¦åŠŸèƒ½ã€‘
1. æ–¹æ³• 1ï¼šSAHI åˆ‡ç‰‡æ¨ç†ï¼ˆé€‚åˆé«˜åˆ†è¾¨ç‡å›¾åƒï¼Œå¾®å°ç›®æ ‡æ£€æµ‹æ›´å¥½ï¼‰
2. æ–¹æ³• 2ï¼šåŸç”Ÿ YOLO æ¨ç†ï¼ˆé€Ÿåº¦å¿«ï¼Œä½œä¸ºå¯¹æ¯”åŸºå‡†ï¼‰
3. è¾“å‡ºå¯¹æ¯”ï¼šæ£€æµ‹æ¡†æ•°é‡ã€å¯è§†åŒ–ç»“æœã€æ€§èƒ½å¯¹æ¯”
4. æ”¯æŒ CLI å‚æ•°ï¼šçµæ´»é…ç½®åˆ‡ç‰‡å¤§å°ã€é‡å ç‡ã€ç½®ä¿¡åº¦ç­‰

ã€ä½¿ç”¨åœºæ™¯ã€‘
- å¯¹æ¯” SAHI å’ŒåŸç”Ÿæ¨ç†çš„æ•ˆæœå·®å¼‚
- å±•ç¤ºå¾®å°ç›®æ ‡æ£€æµ‹èƒ½åŠ›
- éªŒè¯ P2 é«˜åˆ†è¾¨ç‡æ£€æµ‹å¤´çš„ä¼˜åŠ¿
- ä¸ºå®éªŒæŠ¥å‘Šç”Ÿæˆå¯è§†åŒ–ç»“æœ

ã€ç”¨æ³•ã€‘
  # ä½¿ç”¨é»˜è®¤é…ç½®
  python demo_inference.py
  
  # è‡ªå®šä¹‰å‚æ•°
  python demo_inference.py \
      --model runs/ablation/3_yolov11n_p2_dilated/weights/best.pt \
      --image datasets/VisDrone/.../test_image.jpg \
      --slice-height 640 --slice-width 640 \
      --overlap 0.2 --conf 0.25

ã€è¾“å‡ºä½ç½®ã€‘
  demo_result/
  â”œâ”€â”€ sahi_result.jpg          # SAHI åˆ‡ç‰‡æ¨ç†ç»“æœï¼ˆå¾®å°ç›®æ ‡æ›´å¥½ï¼‰
  â””â”€â”€ native_yolo/predict/     # åŸç”Ÿ YOLO æ¨ç†ç»“æœï¼ˆé€Ÿåº¦æ›´å¿«ï¼‰

ã€å¯¹æ¯”ã€‘
  SAHI åˆ‡ç‰‡æ¨ç†ï¼š
  - âœ… å¾®å°ç›®æ ‡å¬å›ç‡æ›´é«˜ï¼ˆé€‚åˆé«˜åˆ†è¾¨ç‡å›¾åƒï¼‰
  - âš ï¸ é€Ÿåº¦è¾ƒæ…¢ï¼ˆéœ€è¦åˆ‡ç‰‡å’Œåˆå¹¶ï¼‰
  
  åŸç”Ÿ YOLO æ¨ç†ï¼š
  - âœ… é€Ÿåº¦å¿«ï¼ˆç›´æ¥æ¨ç†ï¼‰
  - âš ï¸ å¯èƒ½æ¼æ£€å¾®å°ç›®æ ‡ï¼ˆå›¾åƒç¼©æ”¾å¯¼è‡´ä¿¡æ¯æŸå¤±ï¼‰

ã€ç‰¹ç‚¹ã€‘
- âœ… åŒæ¨ç†æ¨¡å¼å¯¹æ¯”ï¼ˆä¸€æ¬¡è¿è¡Œå¾—åˆ°ä¸¤ç§ç»“æœï¼‰
- âœ… SAHI æ›´é€‚åˆå¾®å°ç›®æ ‡æ£€æµ‹
- âœ… è¾“å‡ºæ£€æµ‹æ•°é‡å¯¹æ¯”ï¼Œä¾¿äºåˆ†æ
- âœ… æ”¯æŒè‡ªå®šä¹‰åˆ‡ç‰‡å‚æ•°å’Œç½®ä¿¡åº¦é˜ˆå€¼
"""
import argparse
import os
import sys
from pathlib import Path
from ultralytics import YOLO  # type: ignore
from sahi import AutoDetectionModel
from sahi.predict import get_sliced_prediction


def parse_args():
    parser = argparse.ArgumentParser(description="SAHI + YOLO inference demo")
    parser.add_argument(
        "--model",
        default="runs/ablation/3_yolov11n_p2_dilated/weights/best.pt",
        help="Path to trained weights",
    )
    parser.add_argument(
        "--image",
        default="datasets/VisDrone/VisDrone2019-DET-test-dev/images/0000006_00159_d_0000005.jpg",
        help="Image path for inference",
    )
    parser.add_argument("--output", default="demo_result", help="Output directory")
    parser.add_argument("--slice-height", type=int, default=640, help="Slice height for SAHI")
    parser.add_argument("--slice-width", type=int, default=640, help="Slice width for SAHI")
    parser.add_argument("--overlap", type=float, default=0.2, help="Slice overlap ratio")
    parser.add_argument("--conf", type=float, default=0.25, help="Confidence threshold")
    parser.add_argument("--device", default="cuda:0", help="Device id, e.g., 'cuda:0' or 'cpu'")
    return parser.parse_args()


def main():
    args = parse_args()
    
    # ---------------------------------------------------------
    # æ£€æŸ¥æ–‡ä»¶
    # ---------------------------------------------------------
    if not os.path.exists(args.model):
        print(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model}")
        print("\nğŸ’¡ è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬:")
        print("   python start_train.py")
        sys.exit(1)

    image_path = args.image
    if not os.path.exists(image_path):
        print(f"âš ï¸  è­¦å‘Š: æµ‹è¯•å›¾åƒä¸å­˜åœ¨: {image_path}")
        print("   å°†å°è¯•ä½¿ç”¨æ•°æ®é›†ä¸­çš„ç¬¬ä¸€å¼ å›¾åƒ...")
        
        # å°è¯•æŸ¥æ‰¾ä»»æ„æµ‹è¯•å›¾åƒ
        test_dir = Path("datasets/VisDrone/VisDrone2019-DET-test-dev/images")
        if test_dir.exists():
            images = list(test_dir.glob("*.jpg"))
            if images:
                image_path = str(images[0])
                print(f"âœ… æ‰¾åˆ°æµ‹è¯•å›¾åƒ: {image_path}")
            else:
                print("âŒ é”™è¯¯: æœªæ‰¾åˆ°ä»»ä½•æµ‹è¯•å›¾åƒ")
                sys.exit(1)
        else:
            print("âŒ é”™è¯¯: æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨")
            print("\nğŸ’¡ è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ä¸‹è½½æ•°æ®é›†:")
            print("   python start_train.py")
            sys.exit(1)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output, exist_ok=True)
    
    print("=" * 60)
    print("ğŸ” SAHI åˆ‡ç‰‡æ¨ç†æ¼”ç¤º")
    print("=" * 60)
    print(f"ğŸ“¦ æ¨¡å‹: {args.model}")
    print(f"ğŸ–¼ï¸  å›¾åƒ: {image_path}")
    print(f"âœ‚ï¸  åˆ‡ç‰‡å¤§å°: {args.slice_height}x{args.slice_width}")
    print(f"ğŸ”— é‡å ç‡: {args.overlap * 100}%")
    print(f"ğŸ¯ ç½®ä¿¡åº¦é˜ˆå€¼: {args.conf}")
    print("=" * 60)
    
    # ---------------------------------------------------------
    # æ–¹æ³• 1: ä½¿ç”¨ SAHI (æ¨èç”¨äºé«˜åˆ†è¾¨ç‡å›¾åƒ)
    # ---------------------------------------------------------
    print("\nğŸš€ æ–¹æ³• 1: SAHI åˆ‡ç‰‡æ¨ç† (é€‚ç”¨äºå¾®å°ç›®æ ‡)")
    print("-" * 60)
    
    try:
        # é…ç½® SAHI æ¨¡å‹æ¥å£
        detection_model = AutoDetectionModel.from_pretrained(
            model_type="yolov8",  # SAHI ç›®å‰ä½¿ç”¨ v8 æ¥å£ (v11 å…¼å®¹)
            model_path=args.model,
            confidence_threshold=args.conf,
            device=args.device,
        )
        
        # æ‰§è¡Œåˆ‡ç‰‡æ¨ç†
        print("æ­£åœ¨æ‰§è¡Œåˆ‡ç‰‡æ¨ç†...")
        result = get_sliced_prediction(
            image_path,
            detection_model,
            slice_height=args.slice_height,
            slice_width=args.slice_width,
            overlap_height_ratio=args.overlap,
            overlap_width_ratio=args.overlap,
            verbose=1
        )
        
        # ä¿å­˜ç»“æœ
        sahi_output = os.path.join(args.output, "sahi_result.jpg")
        result.export_visuals(export_dir=args.output)
        print(f"âœ… SAHI æ¨ç†å®Œæˆ! æ£€æµ‹åˆ° {len(result.object_prediction_list)} ä¸ªç›®æ ‡")
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {args.output}/")
        
    except Exception as e:
        print(f"âŒ SAHI æ¨ç†å¤±è´¥: {e}")
        print("   å¯èƒ½åŸå› : SAHI ç‰ˆæœ¬ä¸å…¼å®¹æˆ–æ¨¡å‹æ ¼å¼é—®é¢˜")
    
    # ---------------------------------------------------------
    # æ–¹æ³• 2: åŸç”Ÿ YOLO æ¨ç† (å¯¹æ¯”åŸºå‡†)
    # ---------------------------------------------------------
    print("\nğŸš€ æ–¹æ³• 2: åŸç”Ÿ YOLO æ¨ç† (æ— åˆ‡ç‰‡)")
    print("-" * 60)
    
    try:
        model = YOLO(args.model)
        
        # ç›´æ¥æ¨ç†
        print("æ­£åœ¨æ‰§è¡Œæ ‡å‡†æ¨ç†...")
        results = model.predict(
            image_path,
            conf=args.conf,
            imgsz=640,
            save=True,
            project=args.output,
            name="native_yolo",
            exist_ok=True
        )

        # YOLO ç»“æœä¸­ boxes å¯èƒ½ä¸ºç©ºï¼Œå®‰å…¨åœ°ç»Ÿè®¡æ£€æµ‹æ•°é‡
        det_count = 0
        if results and results[0].boxes is not None:
            det_count = len(results[0].boxes)

        print(f"âœ… åŸç”Ÿæ¨ç†å®Œæˆ! æ£€æµ‹åˆ° {det_count} ä¸ªç›®æ ‡")
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {args.output}/native_yolo/")
        
    except Exception as e:
        print(f"âŒ åŸç”Ÿæ¨ç†å¤±è´¥: {e}")
    
    # ---------------------------------------------------------
    # ç»“æœå¯¹æ¯”
    # ---------------------------------------------------------
    print("\n" + "=" * 60)
    print("ğŸ“Š æ¨ç†ç»“æœå¯¹æ¯”")
    print("=" * 60)
    print("ğŸ’¡ å»ºè®®:")
    print("   - SAHI æ–¹æ³•é€‚ç”¨äºé«˜åˆ†è¾¨ç‡å›¾åƒ (>1920x1080)")
    print("   - åŸç”Ÿæ–¹æ³•æ›´å¿«ï¼Œä½†å¯èƒ½æ¼æ£€å¾®å°ç›®æ ‡")
    print("   - å¯¹æ¯”ä¸¤ç§æ–¹æ³•çš„æ£€æµ‹æ¡†æ•°é‡å’Œä½ç½®")
    print("\nâœ… æ¼”ç¤ºå®Œæˆ! è¯·æŸ¥çœ‹è¾“å‡ºç›®å½•:")
    print(f"   {os.path.abspath(args.output)}")
    print("=" * 60)

if __name__ == "__main__":
    main()